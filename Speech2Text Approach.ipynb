{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset from [here](https://www.kaggle.com/c/tensorflow-speech-recognition-challenge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import Session\n",
    "import os\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = Session(config=config)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing the audio waves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All samples\n",
    "# labels = [\n",
    "#     'left', 'cat', 'wow', 'six', 'go', 'one', 'dog', 'nine', 'sheila', 'yes',\n",
    "#     'down', 'bird', 'tree', 'up', 'eight', 'bed', 'three', 'on', 'house',\n",
    "#     'five', 'seven', 'zero', 'right', 'four', 'no', 'two', 'off', 'happy',\n",
    "#     'stop', 'marvin'\n",
    "# ]\n",
    "\n",
    "# Subsample\n",
    "labels = [\n",
    "    'left', 'go', 'yes', 'down', 'up', 'on', 'right', 'no', 'off', 'stop',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [04:07<00:00, 24.75s/it]\n"
     ]
    }
   ],
   "source": [
    "train_audio_path = 'Data/train/audio'\n",
    "\n",
    "all_wave = []\n",
    "all_label = []\n",
    "for label in tqdm(labels):\n",
    "    waves = [f for f in os.listdir(os.path.join(train_audio_path, label)) if f.endswith('.wav')]\n",
    "    for wav in waves:\n",
    "        samples, sample_rate = librosa.load(os.path.join(train_audio_path, label, wav), sr=16000)\n",
    "        samples = librosa.resample(samples, sample_rate, 8000)\n",
    "        if(len(samples)== 8000) : \n",
    "            all_wave.append(samples)\n",
    "            all_label.append(label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the output labels to integer encoded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "label_enconder = LabelEncoder()\n",
    "y = label_enconder.fit_transform(all_label)\n",
    "classes = list(label_enconder.classes_)\n",
    "y = np_utils.to_categorical(y, num_classes=len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the 2D array to 3D since the input to the conv1d must be a 3D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wave = np.array(all_wave).reshape(-1,8000,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split into train and validation set**\n",
    "\n",
    "Next, we will train the model on 80% of the data and validate on the remaining 20%:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(np.array(all_wave),np.array(y),stratify=y,test_size = 0.2,random_state=777,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional, BatchNormalization, GRU, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization (BatchNo (None, 8000, 1)           4         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 7988, 8)           112       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 2662, 8)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2662, 8)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 2652, 16)          1424      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 884, 16)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 884, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 876, 32)           4640      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 292, 32)           0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 292, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 292, 32)           128       \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 292, 128)          124416    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 292, 128)          198144    \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 128)               198144    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 562,606\n",
      "Trainable params: 562,540\n",
      "Non-trainable params: 66\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, Input, MaxPooling1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = \"true\"\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(8000,1)))\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True))\n",
    "\n",
    "#First Conv1D layer\n",
    "model.add(Conv1D(8,13, padding='valid', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Second Conv1D layer\n",
    "model.add(Conv1D(16, 11, padding='valid', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Third Conv1D layer\n",
    "model.add(Conv1D(32, 9, padding='valid', activation='relu', strides=1))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True))\n",
    "\n",
    "model.add(Bidirectional(GRU(128, return_sequences=True), merge_mode='sum'))\n",
    "model.add(Bidirectional(GRU(128, return_sequences=True), merge_mode='sum'))\n",
    "model.add(Bidirectional(GRU(128, return_sequences=False), merge_mode='sum'))\n",
    "\n",
    "x = BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-3, center=True, scale=True)\n",
    "\n",
    "#Flatten layer\n",
    "# x = Flatten()(x)\n",
    "\n",
    "#Dense Layer 1\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(labels), activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the loss function to be categorical cross-entropy since it is a multi-classification problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='nadam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early stopping and model checkpoints are the callbacks to stop training the neural network at the right time and to save the best model after every epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', \n",
    "                           verbose=1, patience=10, min_delta=0.0001)\n",
    "\n",
    "checkpoint = ModelCheckpoint('speech2text_model.hdf5', monitor='val_acc', \n",
    "                             verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us train the model on a batch size of 32 and evaluate the performance on the holdout set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "533/533 [==============================] - ETA: 0s - loss: 2.3021 - accuracy: 0.1056WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "533/533 [==============================] - 51s 95ms/step - loss: 2.3021 - accuracy: 0.1056 - val_loss: 2.2956 - val_accuracy: 0.1088\n",
      "Epoch 2/100\n",
      "533/533 [==============================] - ETA: 0s - loss: 2.0355 - accuracy: 0.2154WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "533/533 [==============================] - 50s 93ms/step - loss: 2.0355 - accuracy: 0.2154 - val_loss: 1.3184 - val_accuracy: 0.4804\n",
      "Epoch 3/100\n",
      "106/533 [====>.........................] - ETA: 36s - loss: 1.2680 - accuracy: 0.5056"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    x=x_train, \n",
    "    y=y_train,\n",
    "    epochs=100, \n",
    "    callbacks=[early_stop, checkpoint], \n",
    "    batch_size=32, \n",
    "    validation_data=(x_valid,y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diagnostic plot**\n",
    "\n",
    "I’m going to lean on visualization again to understand the performance of the model over a period of time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "pyplot.plot(hist.history['loss'], label='train')\n",
    "pyplot.plot(hist.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save or Loading the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('speech2text_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('speech2text_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the function that predicts text for the given audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s2t_predict(audio, shape_num=8000):\n",
    "    prob=model.predict(audio.reshape(1,shape_num,1))\n",
    "    index=np.argmax(prob[0])\n",
    "    return classes[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction time! Make predictions on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "index=random.randint(0,len(x_valid)-1)\n",
    "samples=x_valid[index].ravel()\n",
    "print(\"Audio:\",classes[np.argmax(y_valid[index])])\n",
    "ipd.Audio(samples, rate=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Text:\",s2t_predict(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best part is yet to come! Here is a script that prompts a user to record voice commands. Record your own voice commands and test it on the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now read the saved voice command and convert it to text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "samplerate = 16000  \n",
    "duration = 1 # seconds\n",
    "filename = 'yes.wav'\n",
    "print(\"start\")\n",
    "mydata = sd.rec(int(samplerate * duration), samplerate=samplerate,\n",
    "    channels=1, blocking=True)\n",
    "print(\"end\")\n",
    "sd.wait()\n",
    "sf.write(filename, mydata, samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the voice commands\n",
    "test, test_rate = librosa.load('yes.wav', sr = 16000)\n",
    "test_sample = librosa.resample(test, test_rate, 8000)\n",
    "print(test_sample.shape)\n",
    "ipd.Audio(test_sample,rate=8000)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting voice commands to text\n",
    "s2t_predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
